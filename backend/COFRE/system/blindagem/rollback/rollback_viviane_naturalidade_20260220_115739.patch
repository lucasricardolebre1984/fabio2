diff --git a/backend/COFRE/persona-skills/VIVIANE.md b/backend/COFRE/persona-skills/VIVIANE.md
index 24f022c..fee513a 100644
--- a/backend/COFRE/persona-skills/VIVIANE.md
+++ b/backend/COFRE/persona-skills/VIVIANE.md
@@ -20,6 +20,7 @@ ESTILO DE RESPOSTA
 REGRAS COMERCIAIS
 - Nao prometer taxa, aprovacao, prazo fechado ou garantia de resultado.
 - Para preco, usar somente valores oficiais da base de regras/precos.
+- Nao informar preco espontaneamente; so quando o cliente pedir valor/preco/custa.
 - Em negociacao final, desconto, excecao juridica ou caso complexo: escalar para humano.
 
 ESCALONAMENTO HUMANO
@@ -32,4 +33,5 @@ HIGIENE DE CONVERSA
 - Nao repetir "com quem eu falo?" depois de nome identificado.
 - Nao repetir "posso transferir agora?" apos cliente confirmar.
 - Nao contradizer dados ja coletados no contexto.
-
+- Se cliente vier com humor (ex.: "ficar rico"), entre no tom com leveza e depois conduza.
+- Se cliente reclamar de tom rapido/robotico, reconheca, ajuste ritmo e continue sem friccao.
diff --git a/backend/COFRE/system/blindagem/BLINDAGEM_INDEX.md b/backend/COFRE/system/blindagem/BLINDAGEM_INDEX.md
index 691c84e..cab39c0 100644
--- a/backend/COFRE/system/blindagem/BLINDAGEM_INDEX.md
+++ b/backend/COFRE/system/blindagem/BLINDAGEM_INDEX.md
@@ -36,6 +36,7 @@ Este arquivo centraliza os artefatos institucionais de blindagem para homologaca
 - `backend/COFRE/system/blindagem/audit/endpoints-runtime-2026-02-20_113105.json`
 - `backend/COFRE/system/blindagem/audit/playwright-whatsapp-conversas-2026-02-20.json`
 - `backend/COFRE/system/blindagem/audit/VIVIANE_WHATSAPP_NO_LOOP_HOTFIX_2026-02-20.md`
+- `backend/COFRE/system/blindagem/audit/VIVIANE_NATURALIDADE_2026-02-20.md`
 
 ## Rollbacks
 - `backend/COFRE/system/blindagem/rollback/rollback_gate2_cca7e3d.patch`
diff --git a/backend/app/services/viva_ia_service.py b/backend/app/services/viva_ia_service.py
index 7700794..4aeb715 100644
--- a/backend/app/services/viva_ia_service.py
+++ b/backend/app/services/viva_ia_service.py
@@ -75,10 +75,10 @@ ESCALA PARA HUMANO:
         self.base_system_prompt = self._load_viviane_persona_prompt(default_prompt)
 
         self.identity_replies = [
-            "Sou a Viviane, consultora da Rezeta, e vou cuidar do seu atendimento.",
-            "Aqui e a Viviane, da Rezeta. Me conta seu objetivo que eu te ajudo.",
-            "Sou a Viviane, consultora de negocios da Rezeta. Vamos resolver isso juntas.",
-            "Viviane falando, da Rezeta. Pode me explicar seu caso que eu te oriento.",
+            "Justa pergunta. Eu sou a Viviane, consultora da Rezeta, e vou te atender no seu ritmo.",
+            "Sou a Viviane, da Rezeta. Se eu acelerar demais, me avisa que ajusto na hora.",
+            "Viviane aqui. A ideia e te ajudar sem enrolacao e sem pressa.",
+            "Eu sou a Viviane, consultora comercial da Rezeta. Seguimos de forma simples e natural.",
         ]
 
         self.handoff_keywords = {
@@ -255,8 +255,13 @@ ESCALA PARA HUMANO:
                 lead["servico"] = servico_inferido
 
         if self._eh_pergunta_identidade_ia(texto):
-            resposta = self._resposta_identidade_variada(contexto)
+            resposta = self._resposta_identidade_variada(
+                contexto=contexto,
+                texto=texto,
+                lead=lead,
+            )
             contexto["lead"] = lead
+            contexto["conversation_mode"] = "descompressao"
             conversa.contexto_ia = contexto
             await db.commit()
             return resposta
@@ -351,6 +356,13 @@ ESCALA PARA HUMANO:
                 return f"Oi, {nome}! Tudo bem? Estou por aqui para te ajudar no que voce precisar."
             return "Oi! Tudo bem? Estou por aqui para te ajudar no que voce precisar."
 
+        if self._is_money_humor_intent(texto) and not self._is_price_question(texto):
+            contexto["lead"] = lead
+            contexto["conversation_mode"] = "descompressao"
+            conversa.contexto_ia = contexto
+            await db.commit()
+            return self._build_money_humor_reply(lead=lead)
+
         if self._is_price_question(texto):
             known_service = service_info or viva_knowledge_service.find_service_from_message(str(lead.get("servico") or ""))
             if known_service:
@@ -429,6 +441,7 @@ ESCALA PARA HUMANO:
             faltantes=faltantes,
             lead=lead,
             missing_field_streak=int(contexto.get("missing_field_streak") or 0),
+            asked_price=self._is_price_question(texto),
         )
 
     def _normalizar(self, texto: str) -> str:
@@ -471,7 +484,21 @@ ESCALA PARA HUMANO:
         )
         return any(pattern in texto for pattern in patterns)
 
-    def _resposta_identidade_variada(self, contexto: Dict[str, object]) -> str:
+    def _resposta_identidade_variada(
+        self,
+        contexto: Dict[str, object],
+        texto: str = "",
+        lead: Optional[Dict[str, str]] = None,
+    ) -> str:
+        if self._is_style_feedback_about_speed_or_price(texto):
+            nome = str((lead or {}).get("nome") or "").strip()
+            prefix = f"{nome}, " if nome else ""
+            return (
+                f"{prefix}voce tem razao: eu fui direta demais agora. "
+                "Vamos no seu ritmo e sem preco por enquanto. "
+                "Quer que eu te explique primeiro como funciona em 2 passos?"
+            )
+
         index = int(contexto.get("identity_reply_index", 0) or 0)
         resposta = self.identity_replies[index % len(self.identity_replies)]
         contexto["identity_reply_index"] = index + 1
@@ -530,6 +557,37 @@ ESCALA PARA HUMANO:
         )
         return any(pattern in texto for pattern in patterns)
 
+    def _is_style_feedback_about_speed_or_price(self, texto: str) -> bool:
+        if not texto:
+            return False
+        patterns = (
+            "nao perguntei preco",
+            "não perguntei preço",
+            "nao perguntei valor",
+            "não perguntei valor",
+            "falou rapido demais",
+            "falou rápido demais",
+            "muito rapido",
+            "muito rápido",
+            "respondeu rapido",
+            "respondeu rápido",
+            "parece robo",
+            "parece robô",
+        )
+        return any(pattern in texto for pattern in patterns)
+
+    def _is_money_humor_intent(self, texto: str) -> bool:
+        if not texto:
+            return False
+        patterns = (
+            "ficar rico",
+            "ficar milionario",
+            "ficar milionário",
+            "ficar bilionario",
+            "ficar bilionário",
+        )
+        return any(pattern in texto for pattern in patterns)
+
     def _build_known_identity_reply(self, lead: Dict[str, str], fallback_phone: str) -> str:
         nome = str(lead.get("nome") or "").strip() or "sem nome confirmado"
         telefone = str(lead.get("telefone") or "").strip() or fallback_phone or "-"
@@ -650,10 +708,13 @@ ESCALA PARA HUMANO:
         faltantes: List[str],
         lead: Dict[str, str],
         missing_field_streak: int = 0,
+        asked_price: bool = False,
     ) -> str:
         """Garante resposta textual valida para envio no WhatsApp."""
         texto = resposta.strip() if isinstance(resposta, str) else ""
         if texto and self._resposta_modelo_valida(texto):
+            if not asked_price:
+                texto = self._remover_preco_nao_solicitado(texto)
             return texto
 
         if faltantes:
@@ -688,6 +749,53 @@ ESCALA PARA HUMANO:
             "Me conta em uma frase seu objetivo para eu te orientar agora."
         )
 
+    def _remover_preco_nao_solicitado(self, texto: str) -> str:
+        if not texto:
+            return texto
+
+        parts = re.split(r"(?<=[.!?])\s+", texto.strip())
+        if len(parts) <= 1:
+            return texto if not self._sentenca_tem_preco(texto) else (
+                "Perfeito. Primeiro te explico como funciona e, se voce quiser, depois te passo os valores."
+            )
+
+        filtered = [part for part in parts if not self._sentenca_tem_preco(part)]
+        if len(filtered) == len(parts):
+            return texto
+        if not filtered:
+            return "Perfeito. Primeiro te explico como funciona e, se voce quiser, depois te passo os valores."
+        ajustado = " ".join(filtered).strip()
+        if ajustado and not ajustado.endswith((".", "!", "?")):
+            ajustado += "."
+        return ajustado
+
+    def _sentenca_tem_preco(self, trecho: str) -> bool:
+        if not trecho:
+            return False
+        lower = trecho.lower()
+        if re.search(r"r\$\s*\d", lower):
+            return True
+        if re.search(r"\b\d{1,3}(?:\.\d{3})*,\d{2}\b", lower):
+            return True
+        clues = (
+            "faixa inicial",
+            "valor inicial",
+            "custa",
+            "preco",
+            "preço",
+            "investimento",
+        )
+        return any(clue in lower for clue in clues)
+
+    def _build_money_humor_reply(self, lead: Dict[str, str]) -> str:
+        nome = str(lead.get("nome") or "").strip()
+        prefix = f"{nome}, " if nome else ""
+        return (
+            f"{prefix}boa meta. "
+            "Nao existe milagre, mas da para organizar seu nome e melhorar seu caminho de credito. "
+            "Quer que eu te explique em 2 passos, sem falar de preco agora?"
+        )
+
     def _build_decompression_reply(self, lead: Dict[str, str], faltantes: List[str]) -> str:
         servico = str(lead.get("servico") or "").strip()
         campo = faltantes[0] if faltantes else "seu objetivo"
@@ -940,6 +1048,8 @@ ESCALA PARA HUMANO:
             "- Para servicos simples (Limpa Nome, Score, Rating), pode conduzir venda direta.\n"
             "- Para servicos complexos, orientar e encaminhar fechamento humano no momento certo.\n"
             "- Diagnostico 360 deve ser sugerido como primeiro passo, salvo excecao de servico simples.\n"
+            "- Nao mencionar preco espontaneamente; so informar preco quando o cliente pedir valor/preco/custa.\n"
+            "- Se o cliente usar humor (ex.: 'ficar rico'), responda com leveza e empatia antes de qualificar.\n"
             "- Responda primeiro ao que o cliente perguntou agora; depois conduza o proximo passo.\n"
             "- Se a mesma pendencia ja foi solicitada 2+ vezes, nao insistir de forma repetitiva."
         )
diff --git a/backend/tests/test_viviane_humanizacao.py b/backend/tests/test_viviane_humanizacao.py
index a533f93..551b352 100644
--- a/backend/tests/test_viviane_humanizacao.py
+++ b/backend/tests/test_viviane_humanizacao.py
@@ -11,6 +11,17 @@ def test_viviane_persona_loaded_from_cofre_file():
     assert "OBJETIVO PRINCIPAL" in service.base_system_prompt
 
 
+def test_identity_reply_acknowledges_price_feedback_naturally():
+    service = VivaIAService()
+    reply = service._resposta_identidade_variada(
+        contexto={},
+        texto="voce e um robo? falou rapido e eu nao perguntei preco",
+        lead={"nome": "Lucas"},
+    )
+    assert "voce tem razao" in reply.lower()
+    assert "sem preco" in reply.lower()
+
+
 def test_who_am_i_reply_contains_known_data():
     service = VivaIAService()
     lead = {
@@ -97,3 +108,23 @@ def test_handoff_start_reply_avoids_repeat_loop():
     reply = service._build_handoff_start_reply({"nome": "Glauco"})
     assert "Vou te transferir agora" in reply
     assert "Nao precisa repetir" in reply
+
+
+def test_money_humor_reply_does_not_force_price():
+    service = VivaIAService()
+    reply = service._build_money_humor_reply({"nome": "Lucas"})
+    assert "boa meta" in reply.lower()
+    assert "sem falar de preco" in reply.lower()
+    assert "R$" not in reply
+
+
+def test_unsolicited_price_is_removed_from_model_text():
+    service = VivaIAService()
+    text = (
+        "Perfeito, isso ajuda no seu objetivo. "
+        "A faixa inicial e R$ 1.380,00 para esse servico. "
+        "Quer que eu te explique em 2 passos?"
+    )
+    cleaned = service._remover_preco_nao_solicitado(text)
+    assert "R$" not in cleaned
+    assert "2 passos" in cleaned
diff --git a/docs/BUGSREPORT.md b/docs/BUGSREPORT.md
index ab38e67..f304c5b 100644
--- a/docs/BUGSREPORT.md
+++ b/docs/BUGSREPORT.md
@@ -106,6 +106,7 @@
 | BUG-122 | Alta | WhatsApp/Webhook | Conversas recebidas com `@lid` eram marcadas como nao entregaveis (`exists:false`) e bloqueavam resposta automatica da VIVA | Resolvido |
 | BUG-123 | Alta | VIVA/Agenda NLU | Comando natural sem data explicita (`viva marque ... as 17 horas`) falhava com pedido de data/hora e quebrava fluxo operacional | Resolvido |
 | BUG-124 | Critica | Viviane/WhatsApp | Fluxo comercial repetia perguntas de nome/cidade/transferencia, perdia contexto e gerava cancelamento de lead no handoff humano | Resolvido |
+| BUG-125 | Alta | Viviane/WhatsApp UX | Tom muito rigido: resposta com preco espontaneo e baixa empatia em perguntas sociais ("voce e robo?", "ficar rico"), gerando desconforto e risco de abandono | Resolvido |
 
 ---
 
@@ -2406,3 +2407,24 @@ Obs operacional: o MiniMax pode retornar `insufficient balance` se a conta/grupo
   - persona Viviane separada no COFRE com arquivo dedicado.
 - validacao tecnica:
   - `pytest backend/tests/test_viviane_humanizacao.py -q`.
+
+### BUG-125: Viviane com tom rigido e preco espontaneo
+**Data:** 2026-02-20  
+**Severidade:** Alta  
+**Descricao:** Em cenarios reais, a Viviane podia responder de forma dura/automatica, antecipar preco sem pergunta do cliente e falhar na empatia em frases sociais/humor.
+**Esperado:** Conversa natural, humana e adaptativa, com preco apenas sob demanda.
+**Status:** Resolvido  
+
+### Atualizacao 2026-02-20 (BUG-125 - naturalidade e controle de preco)
+- backend:
+  - `backend/app/services/viva_ia_service.py`
+  - `backend/COFRE/persona-skills/VIVIANE.md`
+  - `backend/tests/test_viviane_humanizacao.py`
+- ajustes aplicados:
+  - resposta de identidade com empatia quando cliente reclamar de tom rapido/robotico;
+  - comportamento com humor de objetivo financeiro (`ficar rico`) com leveza e sem travar fluxo;
+  - bloqueio de preco espontaneo no pos-processamento de resposta do modelo;
+  - regra de prompt reforcada: preco somente quando cliente pedir;
+  - testes de regressao para naturalidade e remocao de preco nao solicitado.
+- validacao tecnica:
+  - `PYTHONPATH=C:\projetos\fabio2\backend pytest tests/test_viviane_humanizacao.py -q` => `17 passed`.
diff --git a/docs/VIVIANE_HOMOLOGACAO_FINAL_PLANO_2026-02-20.md b/docs/VIVIANE_HOMOLOGACAO_FINAL_PLANO_2026-02-20.md
index 9b4edda..307633d 100644
--- a/docs/VIVIANE_HOMOLOGACAO_FINAL_PLANO_2026-02-20.md
+++ b/docs/VIVIANE_HOMOLOGACAO_FINAL_PLANO_2026-02-20.md
@@ -11,6 +11,7 @@
 - Resposta outbound voltou a chegar no WhatsApp com `@lid` (Evolution v2.3.7).
 - Fluxo de handoff humano foi blindado para evitar repeticao de transferencia.
 - Extracao de nome e cidade ficou mais natural em respostas curtas.
+- Naturalidade conversational reforcada (humor + empatia + sem preco espontaneo).
 - Persona Viviane foi separada em arquivo dedicado no COFRE:
   - `backend/COFRE/persona-skills/VIVIANE.md`
 
@@ -56,4 +57,3 @@
 - Entrega WhatsApp validada em numeros diferentes (sem hardcode).
 - Documentacao atualizada em `docs/` e `backend/COFRE/`.
 - Rollback patch versionado em `backend/COFRE/system/blindagem/rollback/`.
-
